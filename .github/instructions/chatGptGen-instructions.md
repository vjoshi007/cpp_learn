Algorithmic, Structured C++: Write straightforward C-like code. Use fixed-iteration loops (for(int i=0; i<N; i++)), simple arithmetic, and clear control flow. Avoid recursion, dynamic memory allocation or complex OOP (no virtual functions, STL containers, etc.). Put all logic in one (or a few) top-level functions that represent your datapath. For control logic (FSMs or protocol state machines), use an explicit state variable (e.g. an enum or small ac_int state) and switch/if-else constructs. For example, a one-hot multiplexer driven by a state can be coded with a switch(sel){case 1:…} or chained if/else. This yields clean RTL (often one-hot muxes) under Catapult.

Simple Loop Coding: Design loops with constant bounds when possible. HLS works best when loop limits are known; if you need a variable bound, use a constant upper bound and break inside (so the tool can optimize the loop counter). Declare loop counters with minimal bit width (ac_int) or rely on constant bounds so Catapult can infer narrow counters. Avoid complex loop exit logic; for long combinational checks (e.g. comparing 32-bit values each cycle) you may need to simplify or pipeline that logic.

Constants & Parameters: Use const or constexpr (or small #defines) for fixed parameters. Prefer const int/ac_int over bare #define for clarity. Define sizes (e.g. filter lengths, array sizes) in a header or at function scope. Keep global/static variables to a minimum; if you do use static inside a function (for feedback registers or remembering state), be aware it creates hardware registers.

Bit-Accurate Data Types (Algorithmic C)

ac_int and ac_fixed: Include <ac_int.h> and use ac_int<W,S> for signed/unsigned integers of exactly W bits, and <ac_fixed.h> for fixed-point numbers. For example, ac_int<7,false> is a 7-bit unsigned integer, and ac_fixed<16,4,true> is a 16-bit signed fixed-point with 4 integer bits. These types map directly to hardware widths and avoid waste. All basic operators (+,-,*,/,&,|,^) work on ac_int/ac_fixed without extra precision loss. Use them for loop counters, indices, and data paths to minimize area/power. For DSP loops (e.g. FIR filters, FFTs common in wireless), use ac_fixed for coefficients and intermediate sums to get exactly the needed precision, enabling saturation or rounding options.

Saturation & Wrapping: By default, arithmetic on ac_fixed or ac_int wraps on overflow (like RTL shifters) and truncates extra bits. You can enable saturation mode on ac_fixed to clamp on overflow (at the cost of area). In control logic or counters, wrapping may be acceptable; in data paths (filters, gains), consider saturation or rounding settings as needed.

Fixed-Point in Wireless DSP: In wireless algorithms (filters, mod/demod, FFT), floating-point is expensive. Replace floats/doubles with ac_fixed or integers sized to bit-precision. For example, use 12–16 bit fixed-point for filter taps instead of full 32-bit floats, dramatically cutting area/power. Choose bit widths via simulation or analysis so overflow is controlled. In summary, always use bit-accurate types instead of plain int/float to meet PPA goals.

Loop Pipelining and Unrolling

Pipeline for Throughput: Where high throughput is needed (e.g. streaming data or continuous filter), pipeline loops so new iterations start each clock (initiation interval II=1). In Catapult, apply pragmas or directives (or constraints) to pipeline the main loop. A pipelined loop overlaps operations and can achieve one result per cycle. Beware of feedback dependencies: if a loop iteration uses a result from the previous iteration (via a static variable or output), the tool can only pipeline at II equal to that feedback latency. If an operation (like a multiplier) takes multiple cycles, you may need to balance the feedback path by adding registers (e.g. shift-register delays) in C++ to match latencies. In short: pipeline when possible, but insert delays if you need II=1 with feedback.

Loop Unrolling: For small, regular loops (e.g. fixed-size vector ops, FIR taps, small parallel tasks) consider unrolling part or all of the loop. Full unrolling replicates the loop body N times, exploiting parallel hardware (e.g. N multipliers for an N-tap filter). Unrolling improves throughput/latency but increases area. In wireless DSP kernels, it’s common to unroll inner loops (e.g. multiply–accumulate over filter taps) if you have enough hardware. Be cautious: unrolling a loop accessing a single-port memory won’t gain cycles (see Memory section). Always check the schedule: sometimes a rolled (unpipelined) loop can be just as fast when memory is the bottleneck.

Loop Counters & Boundaries: Use small-bit counters or constant bounds to shorten the exit logic. If you need a loop up to a variable limit, set a constant max bound and break when done. This lets HLS use a narrower loop counter. Also, place break at end of body (if at least one iteration always happens) to avoid extra comparators. In general: fix loop bounds where possible to minimize control logic.

Memory & Interface Handling

Pass-by-Value vs Reference: In function arguments, prefer pass-by-value for scalars you can register locally. Catapult will latch pass-by-value inputs into registers at loop start, reducing external reads. Use pass-by-reference (or pointer/array) for bulk data (arrays, streams). E.g. for a 4-word input array, use int din[4] (reference) to imply a memory interface. For control signals or infrequently changed parameters (like thresholds or flags), use pass-by-value so they’re read once.

Unconditional (Wire) vs Conditional (Handshake) I/O: By default, top-level ports are wire interfaces (no handshake). This means the external driver must hold inputs stable when needed, and outputs appear without “ready” signals. For streaming or arbitrated data, use ready/valid or FIFO interfaces (e.g. ac_channel, or Catapult’s ready/send interfaces). In Bluebook terms, “unconditional IO” is wire-like (you must manage timing externally) while “conditional IO” uses handshake to synchronize transfers. When interfacing with other modules or memory, consider ac_channel (Mentor’s FIFO class) for data streams: the tool then automatically inserts valid/ready logic. (In the testbench you’ll write to/read from channels accordingly.)

Arrays & Memories: Top-level arrays become memory interfaces. In ASIC flow they instantiate as black-box RAMs (to be replaced by custom macros). In FPGA flow they infer block RAM. Access patterns matter: sequential, aligned accesses can be merged by HLS into wider cycles. For example, reading two consecutive elements might become one 64-bit wide access if aligned. To allow “memory merging,” ensure reads/writes are on even word boundaries, unconditional when possible, and use simple conditions. If merging isn’t happening, you may need to rewrite loops.

Memory Bottlenecks: The memory interface often limits throughput. A single-port memory can only perform one access per cycle. Unrolling a loop that reads a single-port RAM will NOT improve cycles (and may even break II=1 pipelining). For example, unrolling a 4-iteration loop by 2 on a single-port array still takes 4 cycles – worse, Catapult then can’t schedule II=1. Solution: use multi-port RAMs, distribute buffers (ping-pong), or reorganize data (partition arrays) so multiple reads can happen in parallel. Also consider streaming channels or FIFOs (two-port) when data widths allow.

Interfaces in Wireless/Control: In wireless data paths, high-throughput streaming is common, so wire interfaces (II=1) or ready/valid FIFOs are used. For control/status signals (mode selects, handshakes), wire ports or registers sufficed. Always plan the interface protocol: e.g. for an FFT block, you might use a FIFO (channel) for input samples and ready/valid handshakes for output flags.

Control Logic & Conditional Operations

Simple Conditions: Write if-else or switch with simple boolean expressions. Catapult can merge mutually-exclusive branches into shared logic. Keep conditions flat (avoid very deep nested ifs) so logic can be pipelined. When possible, make branches mutually exclusive to allow resource sharing. For example, if you have two filters and choose one based on a mode bit, use a single if(sel) branchA; else branchB; instead of overlapping conditions.

One-Hot & Priority Selection: One-hot encodings (common in FSMs or multiplexers) synthesize efficiently. The Bluebook shows examples where a one-hot select (e.g. state encoding 1,2,4,8) is used in a switch/if to choose data. For priority logic (e.g. “find first 1 in a vector”), simple loops can be written algorithmically, but may produce long chains. Bluebook suggests dividing tasks or using helper classes (e.g. LOG2_CEIL) for bit-operations to balance performance.

Static State Machines: For control logic that must remember state across cycles (e.g. sequential protocol steps), use a static or static ac_int variable to hold the state. Update it every loop iteration (often a while(1) main loop) via switch(state) or cascaded if statements. Catapult will infer a register for the state and logic for transitions. Try to minimize the number of active state bits (use one-hot or small encodings) to reduce logic. Remember, any loop exit condition (e.g. waiting for an interrupt flag) adds control logic; simpler is better for timing.

Pipeline Feedback & Scheduling

Identify Feedback Paths: If a loop iteration uses data from the previous iteration (e.g. an accumulator, IIR filter, or shift register), that’s a data-feedback loop. In such cases, the minimum II is constrained by the feedback latency. For example, an IIR filter y[n] = a*x[n] + b*y[n-1] has a feedback on y[n-1]. Catapult will create a pipeline and a small FSM (DP-FSM) for this. To improve II, you must balance delays. Bluebook shows inserting delays (static shift registers) so that the feedback arrives after the forward path delay.

Balancing Delays: In a slow-clock design, feedback can be hidden in one cycle (see “Feedback Within One Clock Cycle” example). But at high clock rates, a multi-cycle multiplier or complex logic will require explicitly delaying the feedback data. Insert extra registers (static int d0,d1; d1=d0; d0=acc;) so the feedback path has enough cycles. The rule is delay count = feed-forward latency/II. Use this for accumulators or recursive filters to maintain II=1.

Control Feedback: Complex loop control (variable bounds, breaks) creates long combinational checks. For high-frequency targets, avoid wide comparisons inside loops. Instead, as above, bind loops to constants or use equality on small types. For instance, don’t check a 32-bit interface variable directly; use a 3-bit ac_int counter for a 0–4 range and compare that. The Bluebook’s “Optimized Loop Control” example rewrote the exit test without a subtractor by checking i_old == ctrl where ctrl was 3 bits. This kind of coding ensures the control path meets timing.

IO Scheduling: As mentioned, Catapult freely moves wire (unconditional) I/O in and out of conditions to save registers. But with handshake interfaces (ready/valid), the timing of reads/writes is fixed by the protocol. E.g. a channel read only occurs when ready. When designing for streaming I/O, ensure your code respects the handshake (e.g. check if(!din.empty()) { val = din.read(); ... }). Mismatches between data rates will cause stalls automatically (unlike HDL, where you’d add FIFOs).

Testbench & Reference Modeling

Always Have a Golden C++ Model: Develop a C++ “reference” or “golden” version of your algorithm (possibly floating-point or well-tested code) first. Then write an HLS-friendly version and use your testbench to compare them. Every code change for synthesis must be checked against the original to avoid functional regressions. For example, copy the original function to dut_orig and compare its outputs to dut_synth under the same inputs. Use loops in the testbench to generate stimulus (random or deterministic) and verify all array outputs.

Coverage of Branches: Ensure your test inputs exercise all conditional paths. The Bluebook shows a case where a testbench only tested sel=1 and missed the other branch. Always add tests for each if/else or FSM state transition. This often means writing separate loops or input patterns in the testbench to cover both cases.

Testbench Structure: Keep the testbench outside of the synthesized code. A typical C++ testbench calls the top function in a loop, feeding in data and checking outputs. When using streams or channels, initialize the channels before calling the function (writing data into them). After invocation, read out from output channels. The provided Bluebook examples show converting an array-based design to use ac_channel by writing to the channel in the testbench and then reading back.

Incremental Verification: After each change (optimization or insertion of pragmas), rerun the C++ testbench on the modified code. Even small refactorings (e.g. changing a loop or adding a static) can introduce bugs. The mantra from the Bluebook: “be methodical, and verify your design at every step”. Use assert statements or printouts to flag mismatches immediately